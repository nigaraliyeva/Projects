{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install pandas_dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_dq import dq_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from  xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302      M        17.99         10.38         122.80       1001.0     \n",
       "1    842517      M        20.57         17.77         132.90       1326.0     \n",
       "2  84300903      M        19.69         21.25         130.00       1203.0     \n",
       "3  84348301      M        11.42         20.38          77.58        386.1     \n",
       "4  84358402      M        20.29         14.34         135.10       1297.0     \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0      0.11840           0.27760          0.3001            0.14710         \n",
       "1      0.08474           0.07864          0.0869            0.07017         \n",
       "2      0.10960           0.15990          0.1974            0.12790         \n",
       "3      0.14250           0.28390          0.2414            0.10520         \n",
       "4      0.10030           0.13280          0.1980            0.10430         \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
       "0     0.2419              0.07871          1.0950      0.9053        8.589      \n",
       "1     0.1812              0.05667          0.5435      0.7339        3.398      \n",
       "2     0.2069              0.05999          0.7456      0.7869        4.585      \n",
       "3     0.2597              0.09744          0.4956      1.1560        3.445      \n",
       "4     0.1809              0.05883          0.7572      0.7813        5.438      \n",
       "\n",
       "   area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
       "0  153.40     0.006399         0.04904        0.05373         0.01587        \n",
       "1   74.08     0.005225         0.01308        0.01860         0.01340        \n",
       "2   94.03     0.006150         0.04006        0.03832         0.02058        \n",
       "3   27.23     0.009110         0.07458        0.05661         0.01867        \n",
       "4   94.44     0.011490         0.02461        0.05688         0.01885        \n",
       "\n",
       "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
       "0    0.03003          0.006193            25.38         17.33       \n",
       "1    0.01389          0.003532            24.99         23.41       \n",
       "2    0.02250          0.004571            23.57         25.53       \n",
       "3    0.05963          0.009208            14.91         26.50       \n",
       "4    0.01756          0.005115            22.54         16.67       \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0      184.60         2019.0         0.1622            0.6656         \n",
       "1      158.80         1956.0         0.1238            0.1866         \n",
       "2      152.50         1709.0         0.1444            0.4245         \n",
       "3       98.87          567.7         0.2098            0.8663         \n",
       "4      152.20         1575.0         0.1374            0.2050         \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0      0.7119              0.2654             0.4601       \n",
       "1      0.2416              0.1860             0.2750       \n",
       "2      0.4504              0.2430             0.3613       \n",
       "3      0.6869              0.2575             0.6638       \n",
       "4      0.4000              0.1625             0.2364       \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0          0.11890          \n",
       "1          0.08902          \n",
       "2          0.08758          \n",
       "3          0.17300          \n",
       "4          0.07678          "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\ASUS\\OneDrive\\Desktop\\CourseProjects\\EDA_Breast_Cancer\\breast-cancer.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  569 \n",
      "Number of columns:  32\n"
     ]
    }
   ],
   "source": [
    "print('Number of records: ', df.shape[0],\n",
    "      '\\nNumber of columns: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_count = df['diagnosis'].value_counts(normalize=True)*100\n",
    "classes_count = classes_count.rename(index={'B': 'Benign', 'M': 'Malignant'})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pie(classes_count, labels=classes_count.index, autopct='%1.2f%%',\n",
    "        startangle=90, colors=['#1ac95d', '#c91a1a'], explode=(0, 0.05))\n",
    "plt.title('Diagnosis Percentages')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data insights using pandas_dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a summary report. Change verbose to 1 to see more details on each DQ issue.\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bd21e_row0_col0, #T_bd21e_row1_col0 {\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bd21e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bd21e_level0_col0\" class=\"col_heading level0 col0\" >DQ Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd21e_level0_row0\" class=\"row_heading level0 row0\" >The Good News</th>\n",
       "      <td id=\"T_bd21e_row0_col0\" class=\"data row0 col0\" >There are no duplicate rows in this dataset, There are no duplicate columns in this datatset, There are no zero-variance or low information columns in the dataset., There are no date-time vars in this dataset, There are no columns with missing values in the dataset, There are no categorical columns with rare categories (< 1 percent) in this dataset, There are no columns with infinite values in this dataset , There are no columns with mixed (more than one) dataypes in this dataset, There are no high cardinality columns in this dataset, There is no target given. Hence no target leakage columns detected in the dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd21e_level0_row1\" class=\"row_heading level0 row1\" >The Bad News</th>\n",
       "      <td id=\"T_bd21e_row1_col0\" class=\"data row1 col0\" >There are ID columns in the dataset. Remove them before modeling using Fix_DQ., There are 30 numerical columns, some with outliers. Remove them or use robust statistics., There are 17 columns with >= 0.8 correlation in the dataset. Drop one of them or use dimensionality reduction techniques.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27a9ed17200>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values%</th>\n",
       "      <th>Unique Values%</th>\n",
       "      <th>Minimum Value</th>\n",
       "      <th>Maximum Value</th>\n",
       "      <th>DQ Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>911320502.0</td>\n",
       "      <td>Possible ID column: drop before modeling step.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>object</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.981</td>\n",
       "      <td>28.11</td>\n",
       "      <td>Column has 14 outliers greater than upper bound (21.90) or lower than lower bound(5.58). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.71</td>\n",
       "      <td>39.28</td>\n",
       "      <td>Column has 7 outliers greater than upper bound (30.24) or lower than lower bound(7.73). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>43.79</td>\n",
       "      <td>188.5</td>\n",
       "      <td>Column has 13 outliers greater than upper bound (147.49) or lower than lower bound(31.78). Cap them or remove them., Column has a high correlation with ['radius_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>143.5</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>Column has 25 outliers greater than upper bound (1326.30) or lower than lower bound(-123.30). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>Column has 6 outliers greater than upper bound (0.13) or lower than lower bound(0.06). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>Column has 16 outliers greater than upper bound (0.23) or lower than lower bound(-0.03). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>Column has 18 outliers greater than upper bound (0.28) or lower than lower bound(-0.12). Cap them or remove them., Column has a high correlation with ['compactness_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>Column has 10 outliers greater than upper bound (0.15) or lower than lower bound(-0.06). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.304</td>\n",
       "      <td>Column has 15 outliers greater than upper bound (0.25) or lower than lower bound(0.11). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>Column has 15 outliers greater than upper bound (0.08) or lower than lower bound(0.05). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>2.873</td>\n",
       "      <td>Column has 38 outliers greater than upper bound (0.85) or lower than lower bound(-0.14). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>4.885</td>\n",
       "      <td>Column has 20 outliers greater than upper bound (2.43) or lower than lower bound(-0.13). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.757</td>\n",
       "      <td>21.98</td>\n",
       "      <td>Column has 38 outliers greater than upper bound (5.98) or lower than lower bound(-1.02). Cap them or remove them., Column has a high correlation with ['radius_se']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>6.802</td>\n",
       "      <td>542.2</td>\n",
       "      <td>Column has 65 outliers greater than upper bound (86.20) or lower than lower bound(-23.16). Cap them or remove them., Column has a high correlation with ['area_mean', 'radius_se', 'perimeter_se']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.03113</td>\n",
       "      <td>Column has 30 outliers greater than upper bound (0.01) or lower than lower bound(0.00). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>Column has 28 outliers greater than upper bound (0.06) or lower than lower bound(-0.02). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396</td>\n",
       "      <td>Column has 22 outliers greater than upper bound (0.08) or lower than lower bound(-0.03). Cap them or remove them., Column has a high correlation with ['compactness_se']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05279</td>\n",
       "      <td>Column has 19 outliers greater than upper bound (0.03) or lower than lower bound(-0.00). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.07895</td>\n",
       "      <td>Column has 27 outliers greater than upper bound (0.04) or lower than lower bound(0.00). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.02984</td>\n",
       "      <td>Column has 28 outliers greater than upper bound (0.01) or lower than lower bound(-0.00). Cap them or remove them., Column has a high correlation with ['compactness_se']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>7.93</td>\n",
       "      <td>36.04</td>\n",
       "      <td>Column has 17 outliers greater than upper bound (27.46) or lower than lower bound(4.34). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>12.02</td>\n",
       "      <td>49.54</td>\n",
       "      <td>Column has 5 outliers greater than upper bound (42.68) or lower than lower bound(8.12). Cap them or remove them., Column has a high correlation with ['texture_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>50.41</td>\n",
       "      <td>251.2</td>\n",
       "      <td>Column has 15 outliers greater than upper bound (187.34) or lower than lower bound(22.17). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean', 'radius_worst']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>185.2</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>Column has 35 outliers greater than upper bound (1937.05) or lower than lower bound(-337.75). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean', 'area_se', 'radius_worst', 'perimeter_worst']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>Column has 7 outliers greater than upper bound (0.19) or lower than lower bound(0.07). Cap them or remove them., Column has a high correlation with ['smoothness_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>1.058</td>\n",
       "      <td>Column has 16 outliers greater than upper bound (0.63) or lower than lower bound(-0.14). Cap them or remove them., Column has a high correlation with ['compactness_mean']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.252</td>\n",
       "      <td>Column has 12 outliers greater than upper bound (0.79) or lower than lower bound(-0.29). Cap them or remove them., Column has a high correlation with ['compactness_mean', 'concavity_mean', 'compactness_worst']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291</td>\n",
       "      <td>Column has a high correlation with ['compactness_mean', 'concavity_mean', 'concave points_mean', 'perimeter_worst', 'compactness_worst', 'concavity_worst']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>Column has 23 outliers greater than upper bound (0.42) or lower than lower bound(0.15). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.05504</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>Column has 24 outliers greater than upper bound (0.12) or lower than lower bound(0.04). Cap them or remove them., Column has a high correlation with ['compactness_worst']. Consider dropping one of them.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Data Type  Missing Values% Unique Values%  \\\n",
       "id                          int64        0.0             100        \n",
       "diagnosis                  object        0.0               0        \n",
       "radius_mean               float64        0.0              NA        \n",
       "texture_mean              float64        0.0              NA        \n",
       "perimeter_mean            float64        0.0              NA        \n",
       "area_mean                 float64        0.0              NA        \n",
       "smoothness_mean           float64        0.0              NA        \n",
       "compactness_mean          float64        0.0              NA        \n",
       "concavity_mean            float64        0.0              NA        \n",
       "concave points_mean       float64        0.0              NA        \n",
       "symmetry_mean             float64        0.0              NA        \n",
       "fractal_dimension_mean    float64        0.0              NA        \n",
       "radius_se                 float64        0.0              NA        \n",
       "texture_se                float64        0.0              NA        \n",
       "perimeter_se              float64        0.0              NA        \n",
       "area_se                   float64        0.0              NA        \n",
       "smoothness_se             float64        0.0              NA        \n",
       "compactness_se            float64        0.0              NA        \n",
       "concavity_se              float64        0.0              NA        \n",
       "concave points_se         float64        0.0              NA        \n",
       "symmetry_se               float64        0.0              NA        \n",
       "fractal_dimension_se      float64        0.0              NA        \n",
       "radius_worst              float64        0.0              NA        \n",
       "texture_worst             float64        0.0              NA        \n",
       "perimeter_worst           float64        0.0              NA        \n",
       "area_worst                float64        0.0              NA        \n",
       "smoothness_worst          float64        0.0              NA        \n",
       "compactness_worst         float64        0.0              NA        \n",
       "concavity_worst           float64        0.0              NA        \n",
       "concave points_worst      float64        0.0              NA        \n",
       "symmetry_worst            float64        0.0              NA        \n",
       "fractal_dimension_worst   float64        0.0              NA        \n",
       "\n",
       "                        Minimum Value Maximum Value  \\\n",
       "id                           8670.0     911320502.0   \n",
       "diagnosis                                             \n",
       "radius_mean                   6.981           28.11   \n",
       "texture_mean                   9.71           39.28   \n",
       "perimeter_mean                43.79           188.5   \n",
       "area_mean                     143.5          2501.0   \n",
       "smoothness_mean             0.05263          0.1634   \n",
       "compactness_mean            0.01938          0.3454   \n",
       "concavity_mean                  0.0          0.4268   \n",
       "concave points_mean             0.0          0.2012   \n",
       "symmetry_mean                 0.106           0.304   \n",
       "fractal_dimension_mean      0.04996         0.09744   \n",
       "radius_se                    0.1115           2.873   \n",
       "texture_se                   0.3602           4.885   \n",
       "perimeter_se                  0.757           21.98   \n",
       "area_se                       6.802           542.2   \n",
       "smoothness_se              0.001713         0.03113   \n",
       "compactness_se             0.002252          0.1354   \n",
       "concavity_se                    0.0           0.396   \n",
       "concave points_se               0.0         0.05279   \n",
       "symmetry_se                0.007882         0.07895   \n",
       "fractal_dimension_se       0.000895         0.02984   \n",
       "radius_worst                   7.93           36.04   \n",
       "texture_worst                 12.02           49.54   \n",
       "perimeter_worst               50.41           251.2   \n",
       "area_worst                    185.2          4254.0   \n",
       "smoothness_worst            0.07117          0.2226   \n",
       "compactness_worst           0.02729           1.058   \n",
       "concavity_worst                 0.0           1.252   \n",
       "concave points_worst            0.0           0.291   \n",
       "symmetry_worst               0.1565          0.6638   \n",
       "fractal_dimension_worst     0.05504          0.2075   \n",
       "\n",
       "                                                                                                                                                                            DQ Issue                                                                                                                                                     \n",
       "id                                                                                                                                                                                                                                                                                       Possible ID column: drop before modeling step.  \n",
       "diagnosis                                                                                                                                                                                                                                                                                                                      No issue  \n",
       "radius_mean                                                                                                                                                                                                           Column has 14 outliers greater than upper bound (21.90) or lower than lower bound(5.58). Cap them or remove them.  \n",
       "texture_mean                                                                                                                                                                                                           Column has 7 outliers greater than upper bound (30.24) or lower than lower bound(7.73). Cap them or remove them.  \n",
       "perimeter_mean                                                                                                                  Column has 13 outliers greater than upper bound (147.49) or lower than lower bound(31.78). Cap them or remove them., Column has a high correlation with ['radius_mean']. Consider dropping one of them.  \n",
       "area_mean                                                                                                  Column has 25 outliers greater than upper bound (1326.30) or lower than lower bound(-123.30). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean']. Consider dropping one of them.  \n",
       "smoothness_mean                                                                                                                                                                                                         Column has 6 outliers greater than upper bound (0.13) or lower than lower bound(0.06). Cap them or remove them.  \n",
       "compactness_mean                                                                                                                                                                                                      Column has 16 outliers greater than upper bound (0.23) or lower than lower bound(-0.03). Cap them or remove them.  \n",
       "concavity_mean                                                                                                               Column has 18 outliers greater than upper bound (0.28) or lower than lower bound(-0.12). Cap them or remove them., Column has a high correlation with ['compactness_mean']. Consider dropping one of them.  \n",
       "concave points_mean                                          Column has 10 outliers greater than upper bound (0.15) or lower than lower bound(-0.06). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'compactness_mean', 'concavity_mean']. Consider dropping one of them.  \n",
       "symmetry_mean                                                                                                                                                                                                          Column has 15 outliers greater than upper bound (0.25) or lower than lower bound(0.11). Cap them or remove them.  \n",
       "fractal_dimension_mean                                                                                                                                                                                                 Column has 15 outliers greater than upper bound (0.08) or lower than lower bound(0.05). Cap them or remove them.  \n",
       "radius_se                                                                                                                                                                                                             Column has 38 outliers greater than upper bound (0.85) or lower than lower bound(-0.14). Cap them or remove them.  \n",
       "texture_se                                                                                                                                                                                                            Column has 20 outliers greater than upper bound (2.43) or lower than lower bound(-0.13). Cap them or remove them.  \n",
       "perimeter_se                                                                                                                        Column has 38 outliers greater than upper bound (5.98) or lower than lower bound(-1.02). Cap them or remove them., Column has a high correlation with ['radius_se']. Consider dropping one of them.  \n",
       "area_se                                                                                              Column has 65 outliers greater than upper bound (86.20) or lower than lower bound(-23.16). Cap them or remove them., Column has a high correlation with ['area_mean', 'radius_se', 'perimeter_se']. Consider dropping one of them.  \n",
       "smoothness_se                                                                                                                                                                                                          Column has 30 outliers greater than upper bound (0.01) or lower than lower bound(0.00). Cap them or remove them.  \n",
       "compactness_se                                                                                                                                                                                                        Column has 28 outliers greater than upper bound (0.06) or lower than lower bound(-0.02). Cap them or remove them.  \n",
       "concavity_se                                                                                                                   Column has 22 outliers greater than upper bound (0.08) or lower than lower bound(-0.03). Cap them or remove them., Column has a high correlation with ['compactness_se']. Consider dropping one of them.  \n",
       "concave points_se                                                                                                                                                                                                     Column has 19 outliers greater than upper bound (0.03) or lower than lower bound(-0.00). Cap them or remove them.  \n",
       "symmetry_se                                                                                                                                                                                                            Column has 27 outliers greater than upper bound (0.04) or lower than lower bound(0.00). Cap them or remove them.  \n",
       "fractal_dimension_se                                                                                                           Column has 28 outliers greater than upper bound (0.01) or lower than lower bound(-0.00). Cap them or remove them., Column has a high correlation with ['compactness_se']. Consider dropping one of them.  \n",
       "radius_worst                                                                Column has 17 outliers greater than upper bound (27.46) or lower than lower bound(4.34). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean']. Consider dropping one of them.  \n",
       "texture_worst                                                                                                                     Column has 5 outliers greater than upper bound (42.68) or lower than lower bound(8.12). Cap them or remove them., Column has a high correlation with ['texture_mean']. Consider dropping one of them.  \n",
       "perimeter_worst                                           Column has 15 outliers greater than upper bound (187.34) or lower than lower bound(22.17). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean', 'radius_worst']. Consider dropping one of them.  \n",
       "area_worst               Column has 35 outliers greater than upper bound (1937.05) or lower than lower bound(-337.75). Cap them or remove them., Column has a high correlation with ['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_mean', 'area_se', 'radius_worst', 'perimeter_worst']. Consider dropping one of them.  \n",
       "smoothness_worst                                                                                                                Column has 7 outliers greater than upper bound (0.19) or lower than lower bound(0.07). Cap them or remove them., Column has a high correlation with ['smoothness_mean']. Consider dropping one of them.  \n",
       "compactness_worst                                                                                                            Column has 16 outliers greater than upper bound (0.63) or lower than lower bound(-0.14). Cap them or remove them., Column has a high correlation with ['compactness_mean']. Consider dropping one of them.  \n",
       "concavity_worst                                                                       Column has 12 outliers greater than upper bound (0.79) or lower than lower bound(-0.29). Cap them or remove them., Column has a high correlation with ['compactness_mean', 'concavity_mean', 'compactness_worst']. Consider dropping one of them.  \n",
       "concave points_worst                                                                                                                        Column has a high correlation with ['compactness_mean', 'concavity_mean', 'concave points_mean', 'perimeter_worst', 'compactness_worst', 'concavity_worst']. Consider dropping one of them.  \n",
       "symmetry_worst                                                                                                                                                                                                         Column has 23 outliers greater than upper bound (0.42) or lower than lower bound(0.15). Cap them or remove them.  \n",
       "fractal_dimension_worst                                                                                                      Column has 24 outliers greater than upper bound (0.12) or lower than lower bound(0.04). Cap them or remove them., Column has a high correlation with ['compactness_worst']. Consider dropping one of them.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Suggestions = dq_report(df)\n",
    "Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302      1         17.99         10.38         122.80       1001.0     \n",
       "1    842517      1         20.57         17.77         132.90       1326.0     \n",
       "2  84300903      1         19.69         21.25         130.00       1203.0     \n",
       "3  84348301      1         11.42         20.38          77.58        386.1     \n",
       "4  84358402      1         20.29         14.34         135.10       1297.0     \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0      0.11840           0.27760          0.3001            0.14710         \n",
       "1      0.08474           0.07864          0.0869            0.07017         \n",
       "2      0.10960           0.15990          0.1974            0.12790         \n",
       "3      0.14250           0.28390          0.2414            0.10520         \n",
       "4      0.10030           0.13280          0.1980            0.10430         \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
       "0     0.2419              0.07871          1.0950      0.9053        8.589      \n",
       "1     0.1812              0.05667          0.5435      0.7339        3.398      \n",
       "2     0.2069              0.05999          0.7456      0.7869        4.585      \n",
       "3     0.2597              0.09744          0.4956      1.1560        3.445      \n",
       "4     0.1809              0.05883          0.7572      0.7813        5.438      \n",
       "\n",
       "   area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
       "0  153.40     0.006399         0.04904        0.05373         0.01587        \n",
       "1   74.08     0.005225         0.01308        0.01860         0.01340        \n",
       "2   94.03     0.006150         0.04006        0.03832         0.02058        \n",
       "3   27.23     0.009110         0.07458        0.05661         0.01867        \n",
       "4   94.44     0.011490         0.02461        0.05688         0.01885        \n",
       "\n",
       "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
       "0    0.03003          0.006193            25.38         17.33       \n",
       "1    0.01389          0.003532            24.99         23.41       \n",
       "2    0.02250          0.004571            23.57         25.53       \n",
       "3    0.05963          0.009208            14.91         26.50       \n",
       "4    0.01756          0.005115            22.54         16.67       \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0      184.60         2019.0         0.1622            0.6656         \n",
       "1      158.80         1956.0         0.1238            0.1866         \n",
       "2      152.50         1709.0         0.1444            0.4245         \n",
       "3       98.87          567.7         0.2098            0.8663         \n",
       "4      152.20         1575.0         0.1374            0.2050         \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0      0.7119              0.2654             0.4601       \n",
       "1      0.2416              0.1860             0.2750       \n",
       "2      0.4504              0.2430             0.3613       \n",
       "3      0.6869              0.2575             0.6638       \n",
       "4      0.4000              0.1625             0.2364       \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0          0.11890          \n",
       "1          0.08902          \n",
       "2          0.08758          \n",
       "3          0.17300          \n",
       "4          0.07678          "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      1         17.99         10.38         122.80       1001.0     \n",
       "1      1         20.57         17.77         132.90       1326.0     \n",
       "2      1         19.69         21.25         130.00       1203.0     \n",
       "3      1         11.42         20.38          77.58        386.1     \n",
       "4      1         20.29         14.34         135.10       1297.0     \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0      0.11840           0.27760          0.3001            0.14710         \n",
       "1      0.08474           0.07864          0.0869            0.07017         \n",
       "2      0.10960           0.15990          0.1974            0.12790         \n",
       "3      0.14250           0.28390          0.2414            0.10520         \n",
       "4      0.10030           0.13280          0.1980            0.10430         \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
       "0     0.2419              0.07871          1.0950      0.9053        8.589      \n",
       "1     0.1812              0.05667          0.5435      0.7339        3.398      \n",
       "2     0.2069              0.05999          0.7456      0.7869        4.585      \n",
       "3     0.2597              0.09744          0.4956      1.1560        3.445      \n",
       "4     0.1809              0.05883          0.7572      0.7813        5.438      \n",
       "\n",
       "   area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
       "0  153.40     0.006399         0.04904        0.05373         0.01587        \n",
       "1   74.08     0.005225         0.01308        0.01860         0.01340        \n",
       "2   94.03     0.006150         0.04006        0.03832         0.02058        \n",
       "3   27.23     0.009110         0.07458        0.05661         0.01867        \n",
       "4   94.44     0.011490         0.02461        0.05688         0.01885        \n",
       "\n",
       "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
       "0    0.03003          0.006193            25.38         17.33       \n",
       "1    0.01389          0.003532            24.99         23.41       \n",
       "2    0.02250          0.004571            23.57         25.53       \n",
       "3    0.05963          0.009208            14.91         26.50       \n",
       "4    0.01756          0.005115            22.54         16.67       \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0      184.60         2019.0         0.1622            0.6656         \n",
       "1      158.80         1956.0         0.1238            0.1866         \n",
       "2      152.50         1709.0         0.1444            0.4245         \n",
       "3       98.87          567.7         0.2098            0.8663         \n",
       "4      152.20         1575.0         0.1374            0.2050         \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0      0.7119              0.2654             0.4601       \n",
       "1      0.2416              0.1860             0.2750       \n",
       "2      0.4504              0.2430             0.3613       \n",
       "3      0.6869              0.2575             0.6638       \n",
       "4      0.4000              0.1625             0.2364       \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0          0.11890          \n",
       "1          0.08902          \n",
       "2          0.08758          \n",
       "3          0.17300          \n",
       "4          0.07678          "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['id'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features were created!\n",
      "The new shape of the dataframe:  (569, 41)\n"
     ]
    }
   ],
   "source": [
    "list_of_features = ['radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness', 'concavity', 'concave points', 'symmetry', 'fractal_dimension']\n",
    "count = 0\n",
    "\n",
    "for feature in list_of_features:\n",
    "    df[f'avg_{feature}'] = (df[f'{feature}_mean'] + df[f'{feature}_se'] + df[f'{feature}_worst'])\n",
    "    count += 1\n",
    "\n",
    "print(f'{count} features were created!')\n",
    "\n",
    "print('The new shape of the dataframe: ', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>avg_radius</th>\n",
       "      <th>avg_texture</th>\n",
       "      <th>avg_perimeter</th>\n",
       "      <th>avg_area</th>\n",
       "      <th>avg_smoothness</th>\n",
       "      <th>avg_compactness</th>\n",
       "      <th>avg_concavity</th>\n",
       "      <th>avg_concave points</th>\n",
       "      <th>avg_symmetry</th>\n",
       "      <th>avg_fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>44.4650</td>\n",
       "      <td>28.6153</td>\n",
       "      <td>315.989</td>\n",
       "      <td>3173.40</td>\n",
       "      <td>0.286999</td>\n",
       "      <td>0.99224</td>\n",
       "      <td>1.06573</td>\n",
       "      <td>0.42837</td>\n",
       "      <td>0.73203</td>\n",
       "      <td>0.203803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>46.1035</td>\n",
       "      <td>41.9139</td>\n",
       "      <td>295.098</td>\n",
       "      <td>3356.08</td>\n",
       "      <td>0.213765</td>\n",
       "      <td>0.27832</td>\n",
       "      <td>0.34710</td>\n",
       "      <td>0.26957</td>\n",
       "      <td>0.47009</td>\n",
       "      <td>0.149222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>44.0056</td>\n",
       "      <td>47.5669</td>\n",
       "      <td>287.085</td>\n",
       "      <td>3006.03</td>\n",
       "      <td>0.260150</td>\n",
       "      <td>0.62446</td>\n",
       "      <td>0.68612</td>\n",
       "      <td>0.39148</td>\n",
       "      <td>0.59070</td>\n",
       "      <td>0.152141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>26.8256</td>\n",
       "      <td>48.0360</td>\n",
       "      <td>179.895</td>\n",
       "      <td>981.03</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>1.22478</td>\n",
       "      <td>0.98491</td>\n",
       "      <td>0.38137</td>\n",
       "      <td>0.98313</td>\n",
       "      <td>0.279648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>43.5872</td>\n",
       "      <td>31.7913</td>\n",
       "      <td>292.738</td>\n",
       "      <td>2966.44</td>\n",
       "      <td>0.249190</td>\n",
       "      <td>0.36241</td>\n",
       "      <td>0.65488</td>\n",
       "      <td>0.28565</td>\n",
       "      <td>0.43486</td>\n",
       "      <td>0.140725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>48.1860</td>\n",
       "      <td>50.0460</td>\n",
       "      <td>315.773</td>\n",
       "      <td>3664.70</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.35611</td>\n",
       "      <td>0.70658</td>\n",
       "      <td>0.38504</td>\n",
       "      <td>0.38974</td>\n",
       "      <td>0.131619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>44.5855</td>\n",
       "      <td>68.9630</td>\n",
       "      <td>291.403</td>\n",
       "      <td>3091.04</td>\n",
       "      <td>0.220169</td>\n",
       "      <td>0.31983</td>\n",
       "      <td>0.50500</td>\n",
       "      <td>0.27749</td>\n",
       "      <td>0.45138</td>\n",
       "      <td>0.124198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>36.0364</td>\n",
       "      <td>63.2750</td>\n",
       "      <td>238.425</td>\n",
       "      <td>2030.65</td>\n",
       "      <td>0.204353</td>\n",
       "      <td>0.44901</td>\n",
       "      <td>0.48011</td>\n",
       "      <td>0.21039</td>\n",
       "      <td>0.39398</td>\n",
       "      <td>0.138572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>47.0660</td>\n",
       "      <td>70.3450</td>\n",
       "      <td>330.472</td>\n",
       "      <td>3172.22</td>\n",
       "      <td>0.289322</td>\n",
       "      <td>1.20668</td>\n",
       "      <td>1.36127</td>\n",
       "      <td>0.43364</td>\n",
       "      <td>0.67164</td>\n",
       "      <td>0.200345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>17.6017</td>\n",
       "      <td>56.3380</td>\n",
       "      <td>109.628</td>\n",
       "      <td>468.75</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>0.11272</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.47256</td>\n",
       "      <td>0.132013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0        1         17.99         10.38         122.80       1001.0     \n",
       "1        1         20.57         17.77         132.90       1326.0     \n",
       "2        1         19.69         21.25         130.00       1203.0     \n",
       "3        1         11.42         20.38          77.58        386.1     \n",
       "4        1         20.29         14.34         135.10       1297.0     \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564      1         21.56         22.39         142.00       1479.0     \n",
       "565      1         20.13         28.25         131.20       1261.0     \n",
       "566      1         16.60         28.08         108.30        858.1     \n",
       "567      1         20.60         29.33         140.10       1265.0     \n",
       "568      0          7.76         24.54          47.92        181.0     \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0        0.11840           0.27760          0.30010           0.14710         \n",
       "1        0.08474           0.07864          0.08690           0.07017         \n",
       "2        0.10960           0.15990          0.19740           0.12790         \n",
       "3        0.14250           0.28390          0.24140           0.10520         \n",
       "4        0.10030           0.13280          0.19800           0.10430         \n",
       "..               ...               ...             ...                  ...   \n",
       "564      0.11100           0.11590          0.24390           0.13890         \n",
       "565      0.09780           0.10340          0.14400           0.09791         \n",
       "566      0.08455           0.10230          0.09251           0.05302         \n",
       "567      0.11780           0.27700          0.35140           0.15200         \n",
       "568      0.05263           0.04362          0.00000           0.00000         \n",
       "\n",
       "     symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n",
       "0       0.2419              0.07871          1.0950      0.9053     \n",
       "1       0.1812              0.05667          0.5435      0.7339     \n",
       "2       0.2069              0.05999          0.7456      0.7869     \n",
       "3       0.2597              0.09744          0.4956      1.1560     \n",
       "4       0.1809              0.05883          0.7572      0.7813     \n",
       "..             ...                     ...        ...         ...   \n",
       "564     0.1726              0.05623          1.1760      1.2560     \n",
       "565     0.1752              0.05533          0.7655      2.4630     \n",
       "566     0.1590              0.05648          0.4564      1.0750     \n",
       "567     0.2397              0.07016          0.7260      1.5950     \n",
       "568     0.1587              0.05884          0.3857      1.4280     \n",
       "\n",
       "     perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "0        8.589     153.40     0.006399         0.04904        0.05373     \n",
       "1        3.398      74.08     0.005225         0.01308        0.01860     \n",
       "2        4.585      94.03     0.006150         0.04006        0.03832     \n",
       "3        3.445      27.23     0.009110         0.07458        0.05661     \n",
       "4        5.438      94.44     0.011490         0.02461        0.05688     \n",
       "..            ...      ...            ...             ...           ...   \n",
       "564      7.673     158.70     0.010300         0.02891        0.05198     \n",
       "565      5.203      99.04     0.005769         0.02423        0.03950     \n",
       "566      3.425      48.55     0.005903         0.03731        0.04730     \n",
       "567      5.772      86.22     0.006522         0.06158        0.07117     \n",
       "568      2.548      19.15     0.007189         0.00466        0.00000     \n",
       "\n",
       "     concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "0         0.01587         0.03003          0.006193           25.380      \n",
       "1         0.01340         0.01389          0.003532           24.990      \n",
       "2         0.02058         0.02250          0.004571           23.570      \n",
       "3         0.01867         0.05963          0.009208           14.910      \n",
       "4         0.01885         0.01756          0.005115           22.540      \n",
       "..                 ...          ...                   ...           ...   \n",
       "564       0.02454         0.01114          0.004239           25.450      \n",
       "565       0.01678         0.01898          0.002498           23.690      \n",
       "566       0.01557         0.01318          0.003892           18.980      \n",
       "567       0.01664         0.02324          0.006185           25.740      \n",
       "568       0.00000         0.02676          0.002783            9.456      \n",
       "\n",
       "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0        17.33          184.60         2019.0         0.16220       \n",
       "1        23.41          158.80         1956.0         0.12380       \n",
       "2        25.53          152.50         1709.0         0.14440       \n",
       "3        26.50           98.87          567.7         0.20980       \n",
       "4        16.67          152.20         1575.0         0.13740       \n",
       "..             ...              ...         ...               ...   \n",
       "564      26.40          166.10         2027.0         0.14100       \n",
       "565      38.25          155.00         1731.0         0.11660       \n",
       "566      34.12          126.70         1124.0         0.11390       \n",
       "567      39.42          184.60         1821.0         0.16500       \n",
       "568      30.37           59.16          268.6         0.08996       \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0         0.66560           0.7119              0.2654             0.4601       \n",
       "1         0.18660           0.2416              0.1860             0.2750       \n",
       "2         0.42450           0.4504              0.2430             0.3613       \n",
       "3         0.86630           0.6869              0.2575             0.6638       \n",
       "4         0.20500           0.4000              0.1625             0.2364       \n",
       "..                 ...              ...                   ...             ...   \n",
       "564       0.21130           0.4107              0.2216             0.2060       \n",
       "565       0.19220           0.3215              0.1628             0.2572       \n",
       "566       0.30940           0.3403              0.1418             0.2218       \n",
       "567       0.86810           0.9387              0.2650             0.4087       \n",
       "568       0.06444           0.0000              0.0000             0.2871       \n",
       "\n",
       "     fractal_dimension_worst  avg_radius  avg_texture  avg_perimeter  \\\n",
       "0            0.11890            44.4650     28.6153       315.989      \n",
       "1            0.08902            46.1035     41.9139       295.098      \n",
       "2            0.08758            44.0056     47.5669       287.085      \n",
       "3            0.17300            26.8256     48.0360       179.895      \n",
       "4            0.07678            43.5872     31.7913       292.738      \n",
       "..                       ...         ...          ...            ...   \n",
       "564          0.07115            48.1860     50.0460       315.773      \n",
       "565          0.06637            44.5855     68.9630       291.403      \n",
       "566          0.07820            36.0364     63.2750       238.425      \n",
       "567          0.12400            47.0660     70.3450       330.472      \n",
       "568          0.07039            17.6017     56.3380       109.628      \n",
       "\n",
       "     avg_area  avg_smoothness  avg_compactness  avg_concavity  \\\n",
       "0     3173.40     0.286999         0.99224         1.06573      \n",
       "1     3356.08     0.213765         0.27832         0.34710      \n",
       "2     3006.03     0.260150         0.62446         0.68612      \n",
       "3      981.03     0.361410         1.22478         0.98491      \n",
       "4     2966.44     0.249190         0.36241         0.65488      \n",
       "..        ...             ...              ...            ...   \n",
       "564   3664.70     0.262300         0.35611         0.70658      \n",
       "565   3091.04     0.220169         0.31983         0.50500      \n",
       "566   2030.65     0.204353         0.44901         0.48011      \n",
       "567   3172.22     0.289322         1.20668         1.36127      \n",
       "568    468.75     0.149779         0.11272         0.00000      \n",
       "\n",
       "     avg_concave points  avg_symmetry  avg_fractal_dimension  \n",
       "0          0.42837          0.73203          0.203803         \n",
       "1          0.26957          0.47009          0.149222         \n",
       "2          0.39148          0.59070          0.152141         \n",
       "3          0.38137          0.98313          0.279648         \n",
       "4          0.28565          0.43486          0.140725         \n",
       "..                  ...           ...                    ...  \n",
       "564        0.38504          0.38974          0.131619         \n",
       "565        0.27749          0.45138          0.124198         \n",
       "566        0.21039          0.39398          0.138572         \n",
       "567        0.43364          0.67164          0.200345         \n",
       "568        0.00000          0.47256          0.132013         \n",
       "\n",
       "[569 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of the dataframe:  (569, 61)\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20\n",
    "\n",
    "count = 0\n",
    "\n",
    "features = df.drop(columns=['diagnosis']).columns\n",
    "\n",
    "for i, (feat1, feat2) in enumerate(combinations(features, 2), start=1):\n",
    "    new_feature_name = f'{feat1}_x_{feat2}'\n",
    "    df[new_feature_name] = df[feat1] * df[feat2]\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    if count == max_iter:\n",
    "        break\n",
    "\n",
    "print('The new shape of the dataframe: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>avg_radius</th>\n",
       "      <th>avg_texture</th>\n",
       "      <th>avg_perimeter</th>\n",
       "      <th>avg_area</th>\n",
       "      <th>avg_smoothness</th>\n",
       "      <th>avg_compactness</th>\n",
       "      <th>avg_concavity</th>\n",
       "      <th>avg_concave points</th>\n",
       "      <th>avg_symmetry</th>\n",
       "      <th>avg_fractal_dimension</th>\n",
       "      <th>radius_mean_x_texture_mean</th>\n",
       "      <th>radius_mean_x_perimeter_mean</th>\n",
       "      <th>radius_mean_x_area_mean</th>\n",
       "      <th>radius_mean_x_smoothness_mean</th>\n",
       "      <th>radius_mean_x_compactness_mean</th>\n",
       "      <th>radius_mean_x_concavity_mean</th>\n",
       "      <th>radius_mean_x_concave points_mean</th>\n",
       "      <th>radius_mean_x_symmetry_mean</th>\n",
       "      <th>radius_mean_x_fractal_dimension_mean</th>\n",
       "      <th>radius_mean_x_radius_se</th>\n",
       "      <th>radius_mean_x_texture_se</th>\n",
       "      <th>radius_mean_x_perimeter_se</th>\n",
       "      <th>radius_mean_x_area_se</th>\n",
       "      <th>radius_mean_x_smoothness_se</th>\n",
       "      <th>radius_mean_x_compactness_se</th>\n",
       "      <th>radius_mean_x_concavity_se</th>\n",
       "      <th>radius_mean_x_concave points_se</th>\n",
       "      <th>radius_mean_x_symmetry_se</th>\n",
       "      <th>radius_mean_x_fractal_dimension_se</th>\n",
       "      <th>radius_mean_x_radius_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>44.4650</td>\n",
       "      <td>28.6153</td>\n",
       "      <td>315.989</td>\n",
       "      <td>3173.40</td>\n",
       "      <td>0.286999</td>\n",
       "      <td>0.99224</td>\n",
       "      <td>1.06573</td>\n",
       "      <td>0.42837</td>\n",
       "      <td>0.73203</td>\n",
       "      <td>0.203803</td>\n",
       "      <td>186.7362</td>\n",
       "      <td>2209.1720</td>\n",
       "      <td>18007.990</td>\n",
       "      <td>2.130016</td>\n",
       "      <td>4.994024</td>\n",
       "      <td>5.398799</td>\n",
       "      <td>2.646329</td>\n",
       "      <td>4.351781</td>\n",
       "      <td>1.415993</td>\n",
       "      <td>19.699050</td>\n",
       "      <td>16.286347</td>\n",
       "      <td>154.51611</td>\n",
       "      <td>2759.6660</td>\n",
       "      <td>0.115118</td>\n",
       "      <td>0.882230</td>\n",
       "      <td>0.966603</td>\n",
       "      <td>0.285501</td>\n",
       "      <td>0.540240</td>\n",
       "      <td>0.111412</td>\n",
       "      <td>456.58620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>46.1035</td>\n",
       "      <td>41.9139</td>\n",
       "      <td>295.098</td>\n",
       "      <td>3356.08</td>\n",
       "      <td>0.213765</td>\n",
       "      <td>0.27832</td>\n",
       "      <td>0.34710</td>\n",
       "      <td>0.26957</td>\n",
       "      <td>0.47009</td>\n",
       "      <td>0.149222</td>\n",
       "      <td>365.5289</td>\n",
       "      <td>2733.7530</td>\n",
       "      <td>27275.820</td>\n",
       "      <td>1.743102</td>\n",
       "      <td>1.617625</td>\n",
       "      <td>1.787533</td>\n",
       "      <td>1.443397</td>\n",
       "      <td>3.727284</td>\n",
       "      <td>1.165702</td>\n",
       "      <td>11.179795</td>\n",
       "      <td>15.096323</td>\n",
       "      <td>69.89686</td>\n",
       "      <td>1523.8256</td>\n",
       "      <td>0.107478</td>\n",
       "      <td>0.269056</td>\n",
       "      <td>0.382602</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>0.285717</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>514.04430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>44.0056</td>\n",
       "      <td>47.5669</td>\n",
       "      <td>287.085</td>\n",
       "      <td>3006.03</td>\n",
       "      <td>0.260150</td>\n",
       "      <td>0.62446</td>\n",
       "      <td>0.68612</td>\n",
       "      <td>0.39148</td>\n",
       "      <td>0.59070</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>418.4125</td>\n",
       "      <td>2559.7000</td>\n",
       "      <td>23687.070</td>\n",
       "      <td>2.158024</td>\n",
       "      <td>3.148431</td>\n",
       "      <td>3.886806</td>\n",
       "      <td>2.518351</td>\n",
       "      <td>4.073861</td>\n",
       "      <td>1.181203</td>\n",
       "      <td>14.680864</td>\n",
       "      <td>15.494061</td>\n",
       "      <td>90.27865</td>\n",
       "      <td>1851.4507</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.788781</td>\n",
       "      <td>0.754521</td>\n",
       "      <td>0.405220</td>\n",
       "      <td>0.443025</td>\n",
       "      <td>0.090003</td>\n",
       "      <td>464.09330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>26.8256</td>\n",
       "      <td>48.0360</td>\n",
       "      <td>179.895</td>\n",
       "      <td>981.03</td>\n",
       "      <td>0.361410</td>\n",
       "      <td>1.22478</td>\n",
       "      <td>0.98491</td>\n",
       "      <td>0.38137</td>\n",
       "      <td>0.98313</td>\n",
       "      <td>0.279648</td>\n",
       "      <td>232.7396</td>\n",
       "      <td>885.9636</td>\n",
       "      <td>4409.262</td>\n",
       "      <td>1.627350</td>\n",
       "      <td>3.242138</td>\n",
       "      <td>2.756788</td>\n",
       "      <td>1.201384</td>\n",
       "      <td>2.965774</td>\n",
       "      <td>1.112765</td>\n",
       "      <td>5.659752</td>\n",
       "      <td>13.201520</td>\n",
       "      <td>39.34190</td>\n",
       "      <td>310.9666</td>\n",
       "      <td>0.104036</td>\n",
       "      <td>0.851704</td>\n",
       "      <td>0.646486</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.105155</td>\n",
       "      <td>170.27220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>43.5872</td>\n",
       "      <td>31.7913</td>\n",
       "      <td>292.738</td>\n",
       "      <td>2966.44</td>\n",
       "      <td>0.249190</td>\n",
       "      <td>0.36241</td>\n",
       "      <td>0.65488</td>\n",
       "      <td>0.28565</td>\n",
       "      <td>0.43486</td>\n",
       "      <td>0.140725</td>\n",
       "      <td>290.9586</td>\n",
       "      <td>2741.1790</td>\n",
       "      <td>26316.130</td>\n",
       "      <td>2.035087</td>\n",
       "      <td>2.694512</td>\n",
       "      <td>4.017420</td>\n",
       "      <td>2.116247</td>\n",
       "      <td>3.670461</td>\n",
       "      <td>1.193661</td>\n",
       "      <td>15.363588</td>\n",
       "      <td>15.852577</td>\n",
       "      <td>110.33702</td>\n",
       "      <td>1916.1876</td>\n",
       "      <td>0.233132</td>\n",
       "      <td>0.499337</td>\n",
       "      <td>1.154095</td>\n",
       "      <td>0.382466</td>\n",
       "      <td>0.356292</td>\n",
       "      <td>0.103783</td>\n",
       "      <td>457.33660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>48.1860</td>\n",
       "      <td>50.0460</td>\n",
       "      <td>315.773</td>\n",
       "      <td>3664.70</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.35611</td>\n",
       "      <td>0.70658</td>\n",
       "      <td>0.38504</td>\n",
       "      <td>0.38974</td>\n",
       "      <td>0.131619</td>\n",
       "      <td>482.7284</td>\n",
       "      <td>3061.5200</td>\n",
       "      <td>31887.240</td>\n",
       "      <td>2.393160</td>\n",
       "      <td>2.498804</td>\n",
       "      <td>5.258484</td>\n",
       "      <td>2.994684</td>\n",
       "      <td>3.721256</td>\n",
       "      <td>1.212319</td>\n",
       "      <td>25.354560</td>\n",
       "      <td>27.079360</td>\n",
       "      <td>165.42988</td>\n",
       "      <td>3421.5720</td>\n",
       "      <td>0.222068</td>\n",
       "      <td>0.623300</td>\n",
       "      <td>1.120689</td>\n",
       "      <td>0.529082</td>\n",
       "      <td>0.240178</td>\n",
       "      <td>0.091393</td>\n",
       "      <td>548.70200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>44.5855</td>\n",
       "      <td>68.9630</td>\n",
       "      <td>291.403</td>\n",
       "      <td>3091.04</td>\n",
       "      <td>0.220169</td>\n",
       "      <td>0.31983</td>\n",
       "      <td>0.50500</td>\n",
       "      <td>0.27749</td>\n",
       "      <td>0.45138</td>\n",
       "      <td>0.124198</td>\n",
       "      <td>568.6725</td>\n",
       "      <td>2641.0560</td>\n",
       "      <td>25383.930</td>\n",
       "      <td>1.968714</td>\n",
       "      <td>2.081442</td>\n",
       "      <td>2.898720</td>\n",
       "      <td>1.970928</td>\n",
       "      <td>3.526776</td>\n",
       "      <td>1.113793</td>\n",
       "      <td>15.409515</td>\n",
       "      <td>49.580190</td>\n",
       "      <td>104.73639</td>\n",
       "      <td>1993.6752</td>\n",
       "      <td>0.116130</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.795135</td>\n",
       "      <td>0.337781</td>\n",
       "      <td>0.382067</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>476.87970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>36.0364</td>\n",
       "      <td>63.2750</td>\n",
       "      <td>238.425</td>\n",
       "      <td>2030.65</td>\n",
       "      <td>0.204353</td>\n",
       "      <td>0.44901</td>\n",
       "      <td>0.48011</td>\n",
       "      <td>0.21039</td>\n",
       "      <td>0.39398</td>\n",
       "      <td>0.138572</td>\n",
       "      <td>466.1280</td>\n",
       "      <td>1797.7800</td>\n",
       "      <td>14244.460</td>\n",
       "      <td>1.403530</td>\n",
       "      <td>1.698180</td>\n",
       "      <td>1.535666</td>\n",
       "      <td>0.880132</td>\n",
       "      <td>2.639400</td>\n",
       "      <td>0.937568</td>\n",
       "      <td>7.576240</td>\n",
       "      <td>17.845000</td>\n",
       "      <td>56.85500</td>\n",
       "      <td>805.9300</td>\n",
       "      <td>0.097990</td>\n",
       "      <td>0.619346</td>\n",
       "      <td>0.785180</td>\n",
       "      <td>0.258462</td>\n",
       "      <td>0.218788</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>315.06800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>47.0660</td>\n",
       "      <td>70.3450</td>\n",
       "      <td>330.472</td>\n",
       "      <td>3172.22</td>\n",
       "      <td>0.289322</td>\n",
       "      <td>1.20668</td>\n",
       "      <td>1.36127</td>\n",
       "      <td>0.43364</td>\n",
       "      <td>0.67164</td>\n",
       "      <td>0.200345</td>\n",
       "      <td>604.1980</td>\n",
       "      <td>2886.0600</td>\n",
       "      <td>26059.000</td>\n",
       "      <td>2.426680</td>\n",
       "      <td>5.706200</td>\n",
       "      <td>7.238840</td>\n",
       "      <td>3.131200</td>\n",
       "      <td>4.937820</td>\n",
       "      <td>1.445296</td>\n",
       "      <td>14.955600</td>\n",
       "      <td>32.857000</td>\n",
       "      <td>118.90320</td>\n",
       "      <td>1776.1320</td>\n",
       "      <td>0.134353</td>\n",
       "      <td>1.268548</td>\n",
       "      <td>1.466102</td>\n",
       "      <td>0.342784</td>\n",
       "      <td>0.478744</td>\n",
       "      <td>0.127411</td>\n",
       "      <td>530.24400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>17.6017</td>\n",
       "      <td>56.3380</td>\n",
       "      <td>109.628</td>\n",
       "      <td>468.75</td>\n",
       "      <td>0.149779</td>\n",
       "      <td>0.11272</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.47256</td>\n",
       "      <td>0.132013</td>\n",
       "      <td>190.4304</td>\n",
       "      <td>371.8592</td>\n",
       "      <td>1404.560</td>\n",
       "      <td>0.408409</td>\n",
       "      <td>0.338491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.231512</td>\n",
       "      <td>0.456598</td>\n",
       "      <td>2.993032</td>\n",
       "      <td>11.081280</td>\n",
       "      <td>19.77248</td>\n",
       "      <td>148.6040</td>\n",
       "      <td>0.055787</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207658</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>73.37856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0        1         17.99         10.38         122.80       1001.0     \n",
       "1        1         20.57         17.77         132.90       1326.0     \n",
       "2        1         19.69         21.25         130.00       1203.0     \n",
       "3        1         11.42         20.38          77.58        386.1     \n",
       "4        1         20.29         14.34         135.10       1297.0     \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564      1         21.56         22.39         142.00       1479.0     \n",
       "565      1         20.13         28.25         131.20       1261.0     \n",
       "566      1         16.60         28.08         108.30        858.1     \n",
       "567      1         20.60         29.33         140.10       1265.0     \n",
       "568      0          7.76         24.54          47.92        181.0     \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0        0.11840           0.27760          0.30010           0.14710         \n",
       "1        0.08474           0.07864          0.08690           0.07017         \n",
       "2        0.10960           0.15990          0.19740           0.12790         \n",
       "3        0.14250           0.28390          0.24140           0.10520         \n",
       "4        0.10030           0.13280          0.19800           0.10430         \n",
       "..               ...               ...             ...                  ...   \n",
       "564      0.11100           0.11590          0.24390           0.13890         \n",
       "565      0.09780           0.10340          0.14400           0.09791         \n",
       "566      0.08455           0.10230          0.09251           0.05302         \n",
       "567      0.11780           0.27700          0.35140           0.15200         \n",
       "568      0.05263           0.04362          0.00000           0.00000         \n",
       "\n",
       "     symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n",
       "0       0.2419              0.07871          1.0950      0.9053     \n",
       "1       0.1812              0.05667          0.5435      0.7339     \n",
       "2       0.2069              0.05999          0.7456      0.7869     \n",
       "3       0.2597              0.09744          0.4956      1.1560     \n",
       "4       0.1809              0.05883          0.7572      0.7813     \n",
       "..             ...                     ...        ...         ...   \n",
       "564     0.1726              0.05623          1.1760      1.2560     \n",
       "565     0.1752              0.05533          0.7655      2.4630     \n",
       "566     0.1590              0.05648          0.4564      1.0750     \n",
       "567     0.2397              0.07016          0.7260      1.5950     \n",
       "568     0.1587              0.05884          0.3857      1.4280     \n",
       "\n",
       "     perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "0        8.589     153.40     0.006399         0.04904        0.05373     \n",
       "1        3.398      74.08     0.005225         0.01308        0.01860     \n",
       "2        4.585      94.03     0.006150         0.04006        0.03832     \n",
       "3        3.445      27.23     0.009110         0.07458        0.05661     \n",
       "4        5.438      94.44     0.011490         0.02461        0.05688     \n",
       "..            ...      ...            ...             ...           ...   \n",
       "564      7.673     158.70     0.010300         0.02891        0.05198     \n",
       "565      5.203      99.04     0.005769         0.02423        0.03950     \n",
       "566      3.425      48.55     0.005903         0.03731        0.04730     \n",
       "567      5.772      86.22     0.006522         0.06158        0.07117     \n",
       "568      2.548      19.15     0.007189         0.00466        0.00000     \n",
       "\n",
       "     concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "0         0.01587         0.03003          0.006193           25.380      \n",
       "1         0.01340         0.01389          0.003532           24.990      \n",
       "2         0.02058         0.02250          0.004571           23.570      \n",
       "3         0.01867         0.05963          0.009208           14.910      \n",
       "4         0.01885         0.01756          0.005115           22.540      \n",
       "..                 ...          ...                   ...           ...   \n",
       "564       0.02454         0.01114          0.004239           25.450      \n",
       "565       0.01678         0.01898          0.002498           23.690      \n",
       "566       0.01557         0.01318          0.003892           18.980      \n",
       "567       0.01664         0.02324          0.006185           25.740      \n",
       "568       0.00000         0.02676          0.002783            9.456      \n",
       "\n",
       "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0        17.33          184.60         2019.0         0.16220       \n",
       "1        23.41          158.80         1956.0         0.12380       \n",
       "2        25.53          152.50         1709.0         0.14440       \n",
       "3        26.50           98.87          567.7         0.20980       \n",
       "4        16.67          152.20         1575.0         0.13740       \n",
       "..             ...              ...         ...               ...   \n",
       "564      26.40          166.10         2027.0         0.14100       \n",
       "565      38.25          155.00         1731.0         0.11660       \n",
       "566      34.12          126.70         1124.0         0.11390       \n",
       "567      39.42          184.60         1821.0         0.16500       \n",
       "568      30.37           59.16          268.6         0.08996       \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0         0.66560           0.7119              0.2654             0.4601       \n",
       "1         0.18660           0.2416              0.1860             0.2750       \n",
       "2         0.42450           0.4504              0.2430             0.3613       \n",
       "3         0.86630           0.6869              0.2575             0.6638       \n",
       "4         0.20500           0.4000              0.1625             0.2364       \n",
       "..                 ...              ...                   ...             ...   \n",
       "564       0.21130           0.4107              0.2216             0.2060       \n",
       "565       0.19220           0.3215              0.1628             0.2572       \n",
       "566       0.30940           0.3403              0.1418             0.2218       \n",
       "567       0.86810           0.9387              0.2650             0.4087       \n",
       "568       0.06444           0.0000              0.0000             0.2871       \n",
       "\n",
       "     fractal_dimension_worst  avg_radius  avg_texture  avg_perimeter  \\\n",
       "0            0.11890            44.4650     28.6153       315.989      \n",
       "1            0.08902            46.1035     41.9139       295.098      \n",
       "2            0.08758            44.0056     47.5669       287.085      \n",
       "3            0.17300            26.8256     48.0360       179.895      \n",
       "4            0.07678            43.5872     31.7913       292.738      \n",
       "..                       ...         ...          ...            ...   \n",
       "564          0.07115            48.1860     50.0460       315.773      \n",
       "565          0.06637            44.5855     68.9630       291.403      \n",
       "566          0.07820            36.0364     63.2750       238.425      \n",
       "567          0.12400            47.0660     70.3450       330.472      \n",
       "568          0.07039            17.6017     56.3380       109.628      \n",
       "\n",
       "     avg_area  avg_smoothness  avg_compactness  avg_concavity  \\\n",
       "0     3173.40     0.286999         0.99224         1.06573      \n",
       "1     3356.08     0.213765         0.27832         0.34710      \n",
       "2     3006.03     0.260150         0.62446         0.68612      \n",
       "3      981.03     0.361410         1.22478         0.98491      \n",
       "4     2966.44     0.249190         0.36241         0.65488      \n",
       "..        ...             ...              ...            ...   \n",
       "564   3664.70     0.262300         0.35611         0.70658      \n",
       "565   3091.04     0.220169         0.31983         0.50500      \n",
       "566   2030.65     0.204353         0.44901         0.48011      \n",
       "567   3172.22     0.289322         1.20668         1.36127      \n",
       "568    468.75     0.149779         0.11272         0.00000      \n",
       "\n",
       "     avg_concave points  avg_symmetry  avg_fractal_dimension  \\\n",
       "0          0.42837          0.73203          0.203803          \n",
       "1          0.26957          0.47009          0.149222          \n",
       "2          0.39148          0.59070          0.152141          \n",
       "3          0.38137          0.98313          0.279648          \n",
       "4          0.28565          0.43486          0.140725          \n",
       "..                  ...           ...                    ...   \n",
       "564        0.38504          0.38974          0.131619          \n",
       "565        0.27749          0.45138          0.124198          \n",
       "566        0.21039          0.39398          0.138572          \n",
       "567        0.43364          0.67164          0.200345          \n",
       "568        0.00000          0.47256          0.132013          \n",
       "\n",
       "     radius_mean_x_texture_mean  radius_mean_x_perimeter_mean  \\\n",
       "0             186.7362                     2209.1720            \n",
       "1             365.5289                     2733.7530            \n",
       "2             418.4125                     2559.7000            \n",
       "3             232.7396                      885.9636            \n",
       "4             290.9586                     2741.1790            \n",
       "..                          ...                           ...   \n",
       "564           482.7284                     3061.5200            \n",
       "565           568.6725                     2641.0560            \n",
       "566           466.1280                     1797.7800            \n",
       "567           604.1980                     2886.0600            \n",
       "568           190.4304                      371.8592            \n",
       "\n",
       "     radius_mean_x_area_mean  radius_mean_x_smoothness_mean  \\\n",
       "0           18007.990                   2.130016              \n",
       "1           27275.820                   1.743102              \n",
       "2           23687.070                   2.158024              \n",
       "3            4409.262                   1.627350              \n",
       "4           26316.130                   2.035087              \n",
       "..                       ...                            ...   \n",
       "564         31887.240                   2.393160              \n",
       "565         25383.930                   1.968714              \n",
       "566         14244.460                   1.403530              \n",
       "567         26059.000                   2.426680              \n",
       "568          1404.560                   0.408409              \n",
       "\n",
       "     radius_mean_x_compactness_mean  radius_mean_x_concavity_mean  \\\n",
       "0               4.994024                       5.398799             \n",
       "1               1.617625                       1.787533             \n",
       "2               3.148431                       3.886806             \n",
       "3               3.242138                       2.756788             \n",
       "4               2.694512                       4.017420             \n",
       "..                              ...                           ...   \n",
       "564             2.498804                       5.258484             \n",
       "565             2.081442                       2.898720             \n",
       "566             1.698180                       1.535666             \n",
       "567             5.706200                       7.238840             \n",
       "568             0.338491                       0.000000             \n",
       "\n",
       "     radius_mean_x_concave points_mean  radius_mean_x_symmetry_mean  \\\n",
       "0                2.646329                        4.351781             \n",
       "1                1.443397                        3.727284             \n",
       "2                2.518351                        4.073861             \n",
       "3                1.201384                        2.965774             \n",
       "4                2.116247                        3.670461             \n",
       "..                                 ...                          ...   \n",
       "564              2.994684                        3.721256             \n",
       "565              1.970928                        3.526776             \n",
       "566              0.880132                        2.639400             \n",
       "567              3.131200                        4.937820             \n",
       "568              0.000000                        1.231512             \n",
       "\n",
       "     radius_mean_x_fractal_dimension_mean  radius_mean_x_radius_se  \\\n",
       "0                  1.415993                       19.699050          \n",
       "1                  1.165702                       11.179795          \n",
       "2                  1.181203                       14.680864          \n",
       "3                  1.112765                        5.659752          \n",
       "4                  1.193661                       15.363588          \n",
       "..                                    ...                      ...   \n",
       "564                1.212319                       25.354560          \n",
       "565                1.113793                       15.409515          \n",
       "566                0.937568                        7.576240          \n",
       "567                1.445296                       14.955600          \n",
       "568                0.456598                        2.993032          \n",
       "\n",
       "     radius_mean_x_texture_se  radius_mean_x_perimeter_se  \\\n",
       "0            16.286347                  154.51611           \n",
       "1            15.096323                   69.89686           \n",
       "2            15.494061                   90.27865           \n",
       "3            13.201520                   39.34190           \n",
       "4            15.852577                  110.33702           \n",
       "..                        ...                         ...   \n",
       "564          27.079360                  165.42988           \n",
       "565          49.580190                  104.73639           \n",
       "566          17.845000                   56.85500           \n",
       "567          32.857000                  118.90320           \n",
       "568          11.081280                   19.77248           \n",
       "\n",
       "     radius_mean_x_area_se  radius_mean_x_smoothness_se  \\\n",
       "0          2759.6660                 0.115118             \n",
       "1          1523.8256                 0.107478             \n",
       "2          1851.4507                 0.121094             \n",
       "3           310.9666                 0.104036             \n",
       "4          1916.1876                 0.233132             \n",
       "..                     ...                          ...   \n",
       "564        3421.5720                 0.222068             \n",
       "565        1993.6752                 0.116130             \n",
       "566         805.9300                 0.097990             \n",
       "567        1776.1320                 0.134353             \n",
       "568         148.6040                 0.055787             \n",
       "\n",
       "     radius_mean_x_compactness_se  radius_mean_x_concavity_se  \\\n",
       "0              0.882230                     0.966603            \n",
       "1              0.269056                     0.382602            \n",
       "2              0.788781                     0.754521            \n",
       "3              0.851704                     0.646486            \n",
       "4              0.499337                     1.154095            \n",
       "..                            ...                         ...   \n",
       "564            0.623300                     1.120689            \n",
       "565            0.487750                     0.795135            \n",
       "566            0.619346                     0.785180            \n",
       "567            1.268548                     1.466102            \n",
       "568            0.036162                     0.000000            \n",
       "\n",
       "     radius_mean_x_concave points_se  radius_mean_x_symmetry_se  \\\n",
       "0               0.285501                      0.540240            \n",
       "1               0.275638                      0.285717            \n",
       "2               0.405220                      0.443025            \n",
       "3               0.213211                      0.680975            \n",
       "4               0.382466                      0.356292            \n",
       "..                               ...                        ...   \n",
       "564             0.529082                      0.240178            \n",
       "565             0.337781                      0.382067            \n",
       "566             0.258462                      0.218788            \n",
       "567             0.342784                      0.478744            \n",
       "568             0.000000                      0.207658            \n",
       "\n",
       "     radius_mean_x_fractal_dimension_se  radius_mean_x_radius_worst  \n",
       "0                 0.111412                        456.58620          \n",
       "1                 0.072653                        514.04430          \n",
       "2                 0.090003                        464.09330          \n",
       "3                 0.105155                        170.27220          \n",
       "4                 0.103783                        457.33660          \n",
       "..                                  ...                         ...  \n",
       "564               0.091393                        548.70200          \n",
       "565               0.050285                        476.87970          \n",
       "566               0.064607                        315.06800          \n",
       "567               0.127411                        530.24400          \n",
       "568               0.021596                         73.37856          \n",
       "\n",
       "[569 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(corr_matrix, cmap='magma', annot=False)\n",
    "\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = corr_matrix['diagnosis'].drop('diagnosis')\n",
    "\n",
    "corr_matrix = corr_matrix.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(6.4, 15))\n",
    "\n",
    "sns.heatmap(corr_matrix.to_frame(), cmap='magma', annot=False)\n",
    "\n",
    "plt.title('Correlation with the target Diagnosis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=7, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  512 \n",
      "Number of columns:  10\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "x_train_pca = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n",
    "\n",
    "print('Number of records: ', x_train_pca.shape[0],\n",
    "      '\\nNumber of columns: ', x_train_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_df = pd.DataFrame(x_train_pca)\n",
    "corr_matrix = n_df.corr()\n",
    "\n",
    "sns.heatmap(corr_matrix, cmap='magma', annot=False)\n",
    "\n",
    "plt.title('Correlation Matrix - PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "x_train_pca95 = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca95 = pca.transform(x_test_scaled)\n",
    "\n",
    "param_grid_DT = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=7)\n",
    "\n",
    "def build_DT_model(parameters, cv, x_train_pca, x_test_pca):\n",
    "    model = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid_DT, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(x_train_pca, y_train)\n",
    "\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test_pca)\n",
    "\n",
    "    print(\"\\nClassification Report on Test Set: \")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    build_DT_model(param_grid_DT, skf, x_train_pca95, x_test_pca95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Score:  0.939422084623323\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        36\n",
      "           1       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.95      0.94      0.94        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9374383671597294\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        36\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.91      0.90      0.90        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\initializers.py:28: UserWarning: Unable to introspect viztracer state: maximum recursion depth exceeded\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1469\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1469\u001b[0m     islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mislice(iterator, big_batch_size))\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1471\u001b[0m     \u001b[38;5;66;03m# Handle the fact that the generator of task raised an\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;66;03m# exception. As this part of the code can be executed in\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;66;03m# a thread internal to the backend, register a task with\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;66;03m# an error that will be raised in the user's thread.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:75\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:971\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    966\u001b[0m         )\n\u001b[0;32m    967\u001b[0m     )\n\u001b[0;32m    969\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    970\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 971\u001b[0m         clone(base_estimator),\n\u001b[0;32m    972\u001b[0m         X,\n\u001b[0;32m    973\u001b[0m         y,\n\u001b[0;32m    974\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    975\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    976\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    977\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    978\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    984\u001b[0m     )\n\u001b[0;32m    985\u001b[0m )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:94\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[38;5;241m=\u001b[39msafe)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:300\u001b[0m, in \u001b[0;36mBaseEstimator.__sklearn_clone__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_clone__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _clone_parametrized(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:125\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m    124\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m--> 125\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:247\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    246\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[0;32m    248\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:212\u001b[0m, in \u001b[0;36mBaseEstimator._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# introspect the constructor arguments to find the model parameters\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# to represent\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m init_signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# Consider the constructor parameters excluding 'self'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\inspect.py:3341\u001b[0m, in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Signature\u001b[38;5;241m.\u001b[39mfrom_callable(obj, follow_wrapped\u001b[38;5;241m=\u001b[39mfollow_wrapped,\n\u001b[0;32m   3342\u001b[0m                                \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\inspect.py:3081\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[1;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3080\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   3082\u001b[0m                                 follow_wrapper_chains\u001b[38;5;241m=\u001b[39mfollow_wrapped,\n\u001b[0;32m   3083\u001b[0m                                 \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\inspect.py:2593\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[0;32m   2591\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[0;32m   2592\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[1;32m-> 2593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[0;32m   2594\u001b[0m                                     skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[0;32m   2595\u001b[0m                                     \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[0;32m   2597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\inspect.py:2438\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   2437\u001b[0m annotation \u001b[38;5;241m=\u001b[39m annotations\u001b[38;5;241m.\u001b[39mget(name, _empty)\n\u001b[1;32m-> 2438\u001b[0m parameters\u001b[38;5;241m.\u001b[39mappend(Parameter(name, annotation\u001b[38;5;241m=\u001b[39mannotation,\n\u001b[0;32m   2439\u001b[0m                             kind\u001b[38;5;241m=\u001b[39mkind))\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m posonly_left:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\inspect.py:2741\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[1;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[0;32m   2740\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2741\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind \u001b[38;5;241m=\u001b[39m _ParameterKind(kind)\n\u001b[0;32m   2742\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\enum.py:757\u001b[0m, in \u001b[0;36mEnumType.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start, boundary, *values)\u001b[0m\n\u001b[0;32m    756\u001b[0m         value \u001b[38;5;241m=\u001b[39m (value, names) \u001b[38;5;241m+\u001b[39m values\n\u001b[1;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\initializers.py:15\u001b[0m, in \u001b[0;36m_make_viztracer_initializer_and_initargs\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mviztracer\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     tracer \u001b[38;5;241m=\u001b[39m viztracer\u001b[38;5;241m.\u001b[39mget_tracer()\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1357\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:418\u001b[0m, in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:311\u001b[0m, in \u001b[0;36macquire\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:170\u001b[0m, in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m x_train_pca99 \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(x_train_scaled)\n\u001b[0;32m      3\u001b[0m x_test_pca99 \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(x_test_scaled)\n\u001b[1;32m----> 5\u001b[0m build_DT_model(param_grid_DT, skf, x_train_pca99, x_test_pca99)\n",
      "Cell \u001b[1;32mIn[20], line 29\u001b[0m, in \u001b[0;36mbuild_DT_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 29\u001b[0m build_DT_model(param_grid_DT, skf, x_train_pca95, x_test_pca95)\n",
      "Cell \u001b[1;32mIn[20], line 29\u001b[0m, in \u001b[0;36mbuild_DT_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 29\u001b[0m build_DT_model(param_grid_DT, skf, x_train_pca95, x_test_pca95)\n",
      "    \u001b[1;31m[... skipping similar frames: build_DT_model at line 29 (2951 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[20], line 29\u001b[0m, in \u001b[0;36mbuild_DT_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 29\u001b[0m build_DT_model(param_grid_DT, skf, x_train_pca95, x_test_pca95)\n",
      "Cell \u001b[1;32mIn[20], line 18\u001b[0m, in \u001b[0;36mbuild_DT_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     16\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_DT, cv\u001b[38;5;241m=\u001b[39mskf, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(x_train_pca, y_train)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1023\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1570\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:969\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    966\u001b[0m         )\n\u001b[0;32m    967\u001b[0m     )\n\u001b[1;32m--> 969\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    970\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    971\u001b[0m         clone(base_estimator),\n\u001b[0;32m    972\u001b[0m         X,\n\u001b[0;32m    973\u001b[0m         y,\n\u001b[0;32m    974\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    975\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    976\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    977\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    978\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    984\u001b[0m     )\n\u001b[0;32m    985\u001b[0m )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1703\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_abort()\n\u001b[0;32m   1704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1614\u001b[0m, in \u001b[0;36mParallel._abort\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[1;32m-> 1614\u001b[0m     backend\u001b[38;5;241m.\u001b[39mabort_everything(ensure_ready\u001b[38;5;241m=\u001b[39mensure_ready)\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\_parallel_backends.py:624\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigure(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39mn_jobs, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\_parallel_backends.py:538\u001b[0m, in \u001b[0;36mLokyBackend.configure\u001b[1;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FallbackToBackend(\n\u001b[0;32m    536\u001b[0m         SequentialBackend(nesting_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesting_level))\n\u001b[1;32m--> 538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m get_memmapping_executor(\n\u001b[0;32m    539\u001b[0m     n_jobs, timeout\u001b[38;5;241m=\u001b[39midle_worker_timeout,\n\u001b[0;32m    540\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_worker_env(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs),\n\u001b[0;32m    541\u001b[0m     context_id\u001b[38;5;241m=\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmemmappingexecutor_args)\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel \u001b[38;5;241m=\u001b[39m parallel\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_jobs\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\executor.py:20\u001b[0m, in \u001b[0;36mget_memmapping_executor\u001b[1;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_memmapping_executor\u001b[39m(n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MemmappingExecutor\u001b[38;5;241m.\u001b[39mget_memmapping_executor(n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\executor.py:52\u001b[0m, in \u001b[0;36mMemmappingExecutor.get_memmapping_executor\u001b[1;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# reducers access the temporary folder in which to store temporary\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# pickles through a call to manager.resolve_temp_folder_name. resolving\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# the folder name dynamically is useful to use different folders across\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# calls of a same reusable executor\u001b[39;00m\n\u001b[0;32m     48\u001b[0m job_reducers, result_reducers \u001b[38;5;241m=\u001b[39m get_memmapping_reducers(\n\u001b[0;32m     49\u001b[0m     unlink_on_gc_collect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     temp_folder_resolver\u001b[38;5;241m=\u001b[39mmanager\u001b[38;5;241m.\u001b[39mresolve_temp_folder_name,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbackend_args)\n\u001b[1;32m---> 52\u001b[0m _executor, executor_is_reused \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_reusable_executor(\n\u001b[0;32m     53\u001b[0m     n_jobs, job_reducers\u001b[38;5;241m=\u001b[39mjob_reducers, result_reducers\u001b[38;5;241m=\u001b[39mresult_reducers,\n\u001b[0;32m     54\u001b[0m     reuse\u001b[38;5;241m=\u001b[39mreuse, timeout\u001b[38;5;241m=\u001b[39mtimeout, initializer\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[0;32m     55\u001b[0m     initargs\u001b[38;5;241m=\u001b[39minitargs, env\u001b[38;5;241m=\u001b[39menv\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m executor_is_reused:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Only set a _temp_folder_manager for new executors. Reused\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# executors already have a _temporary_folder_manager that must not\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# be re-assigned like that because it is referenced in various\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# places in the reducing machinery of the executor.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     _executor\u001b[38;5;241m.\u001b[39m_temp_folder_manager \u001b[38;5;241m=\u001b[39m manager\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:210\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.get_reusable_executor\u001b[1;34m(cls, max_workers, context, timeout, kill_workers, reuse, job_reducers, result_reducers, initializer, initargs, env)\u001b[0m\n\u001b[0;32m    208\u001b[0m     _executor \u001b[38;5;241m=\u001b[39m executor \u001b[38;5;241m=\u001b[39m _executor_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Recursive call to build a new instance\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_reusable_executor(\n\u001b[0;32m    211\u001b[0m         max_workers\u001b[38;5;241m=\u001b[39mmax_workers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    212\u001b[0m     )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     mp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReusing existing executor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_workers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutor\u001b[38;5;241m.\u001b[39m_max_workers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:182\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.get_reusable_executor\u001b[1;34m(cls, max_workers, context, timeout, kill_workers, reuse, job_reducers, result_reducers, initializer, initargs, env)\u001b[0m\n\u001b[0;32m    180\u001b[0m     executor_id \u001b[38;5;241m=\u001b[39m _get_next_executor_id()\n\u001b[0;32m    181\u001b[0m     _executor_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m--> 182\u001b[0m     _executor \u001b[38;5;241m=\u001b[39m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    183\u001b[0m         _executor_lock,\n\u001b[0;32m    184\u001b[0m         max_workers\u001b[38;5;241m=\u001b[39mmax_workers,\n\u001b[0;32m    185\u001b[0m         executor_id\u001b[38;5;241m=\u001b[39mexecutor_id,\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reuse \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:118\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.__init__\u001b[1;34m(self, submit_resize_lock, max_workers, context, timeout, executor_id, job_reducers, result_reducers, initializer, initargs, env)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    107\u001b[0m     submit_resize_lock,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m ):\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    119\u001b[0m         max_workers\u001b[38;5;241m=\u001b[39mmax_workers,\n\u001b[0;32m    120\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    121\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    122\u001b[0m         job_reducers\u001b[38;5;241m=\u001b[39mjob_reducers,\n\u001b[0;32m    123\u001b[0m         result_reducers\u001b[38;5;241m=\u001b[39mresult_reducers,\n\u001b[0;32m    124\u001b[0m         initializer\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[0;32m    125\u001b[0m         initargs\u001b[38;5;241m=\u001b[39minitargs,\n\u001b[0;32m    126\u001b[0m         env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor_id \u001b[38;5;241m=\u001b[39m executor_id\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock \u001b[38;5;241m=\u001b[39m submit_resize_lock\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1087\u001b[0m, in \u001b[0;36mProcessPoolExecutor.__init__\u001b[1;34m(self, max_workers, job_reducers, result_reducers, timeout, context, initializer, initargs, env)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context \u001b[38;5;241m=\u001b[39m context\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env \u001b[38;5;241m=\u001b[39m env\n\u001b[1;32m-> 1087\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initializer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initargs \u001b[38;5;241m=\u001b[39m _prepare_initializer(\n\u001b[0;32m   1088\u001b[0m     initializer, initargs\n\u001b[0;32m   1089\u001b[0m )\n\u001b[0;32m   1090\u001b[0m _check_max_depth(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_reducers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\initializers.py:78\u001b[0m, in \u001b[0;36m_prepare_initializer\u001b[1;34m(initializer, initargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitializer must be a callable, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitializer\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Introspect runtime to determine if we need to propagate the viztracer\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# profiler information to the workers:\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_initializers(\n\u001b[0;32m     76\u001b[0m     [\n\u001b[0;32m     77\u001b[0m         (initializer, initargs),\n\u001b[1;32m---> 78\u001b[0m         _make_viztracer_initializer_and_initargs(),\n\u001b[0;32m     79\u001b[0m     ]\n\u001b[0;32m     80\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\externals\\loky\\initializers.py:28\u001b[0m, in \u001b[0;36m_make_viztracer_initializer_and_initargs\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# In case viztracer's API evolve, we do not want to crash loky but\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# we want to know about it to be able to update loky.\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to introspect viztracer state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, ()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\warnings.py:115\u001b[0m, in \u001b[0;36m_showwarnmsg\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    112\u001b[0m         sw(msg\u001b[38;5;241m.\u001b[39mmessage, msg\u001b[38;5;241m.\u001b[39mcategory, msg\u001b[38;5;241m.\u001b[39mfilename, msg\u001b[38;5;241m.\u001b[39mlineno,\n\u001b[0;32m    113\u001b[0m            msg\u001b[38;5;241m.\u001b[39mfile, msg\u001b[38;5;241m.\u001b[39mline)\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m _showwarnmsg_impl(msg)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\warnings.py:30\u001b[0m, in \u001b[0;36m_showwarnmsg_impl\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m     28\u001b[0m text \u001b[38;5;241m=\u001b[39m _formatwarnmsg(msg)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(text)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# the file (probably stderr) is invalid - this warning gets lost.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\ipykernel\\iostream.py:694\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_flush()\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\ipykernel\\iostream.py:590\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(_schedule_in_thread)\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99)\n",
    "x_train_pca99 = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca99 = pca.transform(x_test_scaled)\n",
    "\n",
    "build_DT_model(param_grid_DT, skf, x_train_pca99, x_test_pca99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.999)\n",
    "x_train_pca999 = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca999 = pca.transform(x_test_scaled)\n",
    "\n",
    "build_DT_model(param_grid_DT, skf, x_train_pca999, x_test_pca999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_RF = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 3, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "def build_RF_model(parameters, cv, x_train_pca, x_test_pca):\n",
    "    model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid_DT, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(x_train_pca, y_train)\n",
    "\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "    print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test_pca)\n",
    "\n",
    "    print('\\nClassification Report on Test Set: ')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    build_RF_model(param_grid_RF, skf, x_train_pca95, x_test_pca95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best Score:  0.943343653250774\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        36\n",
      "           1       0.86      0.90      0.88        21\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.90      0.91      0.91        57\n",
      "weighted avg       0.91      0.91      0.91        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n",
      "Best Parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.9472193555784886\n",
      "\n",
      "Classification Report on Test Set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        36\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.92      0.92      0.92        57\n",
      "weighted avg       0.93      0.93      0.93        57\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m build_RF_model(param_grid_RF, skf, x_train_pca99, x_test_pca99)\n",
      "Cell \u001b[1;32mIn[24], line 23\u001b[0m, in \u001b[0;36mbuild_RF_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 23\u001b[0m build_RF_model(param_grid_RF, skf, x_train_pca95, x_test_pca95)\n",
      "Cell \u001b[1;32mIn[24], line 23\u001b[0m, in \u001b[0;36mbuild_RF_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 23\u001b[0m build_RF_model(param_grid_RF, skf, x_train_pca95, x_test_pca95)\n",
      "    \u001b[1;31m[... skipping similar frames: build_RF_model at line 23 (41 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[24], line 23\u001b[0m, in \u001b[0;36mbuild_RF_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 23\u001b[0m build_RF_model(param_grid_RF, skf, x_train_pca95, x_test_pca95)\n",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m, in \u001b[0;36mbuild_RF_model\u001b[1;34m(parameters, cv, x_train_pca, x_test_pca)\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_DT, cv\u001b[38;5;241m=\u001b[39mskf, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(x_train_pca, y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1061\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1059\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    190\u001b[0m         X,\n\u001b[0;32m    191\u001b[0m         y,\n\u001b[0;32m    192\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    193\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\mynewenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "build_RF_model(param_grid_RF, skf, x_train_pca99, x_test_pca99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_RF_model(param_grid_RF, skf, x_train_pca99, x_test_pca999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
